from sklearn.model_selection import GridSearchCV, KFold
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
import numpy as np

# Assuming X_train and y_train are your training data

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)

# Define the model
model = LinearRegression()

# Define hyperparameters to tune
param_grid = {
    'fit_intercept': [True, False],
    # You can add more hyperparameters to tune here
}

# Define cross-validation strategy
cv = KFold(n_splits=5, shuffle=True, random_state=42)

from sklearn.model_selection import StratifiedKFold

# Define cross-validation strategy (Stratified K-Fold)
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Grid search cross-validation
grid_search = GridSearchCV(model, param_grid=param_grid, cv=cv, scoring='neg_mean_squared_error')


# Grid search cross-validation
grid_search = GridSearchCV(model, param_grid=param_grid, cv=cv, scoring='neg_mean_squared_error')
grid_search.fit(X_train_scaled, y_train)

# Get best model and its hyperparameters
best_model = grid_search.best_estimator_
best_params = grid_search.best_params_

# Scale the test features
X_test_scaled = scaler.transform(X_test)

# Evaluate best model on test data
y_pred = best_model.predict(X_test_scaled)
test_mse = mean_squared_error(y_test, y_pred)

print("Best Hyperparameters:", best_params)
print("Test MSE:", test_mse)
--------------------------------------------------------

  
  
