from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.datasets import make_regression
import numpy as np

# Generate some example data
X, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=42)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Linear Regression
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Lasso Regression
lasso_model = Lasso(alpha=0.1)  # Adjust alpha for regularization strength
lasso_model.fit(X_train, y_train)

# Ridge Regression
ridge_model = Ridge(alpha=1.0)  # Adjust alpha for regularization strength
ridge_model.fit(X_train, y_train)

# Evaluate models
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    return mse

lr_mse = evaluate_model(lr_model, X_test, y_test)
lasso_mse = evaluate_model(lasso_model, X_test, y_test)
ridge_mse = evaluate_model(ridge_model, X_test, y_test)

print("Linear Regression MSE:", lr_mse)
print("Lasso Regression MSE:", lasso_mse)
print("Ridge Regression MSE:", ridge_mse)


--------------------------------------------


from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.datasets import make_regression
import numpy as np

# Generate some example data
X, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=42)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Linear Regression
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Lasso Regression
lasso_model = Lasso(alpha=0.1)  # Adjust alpha for regularization strength
lasso_model.fit(X_train, y_train)

# Ridge Regression
ridge_model = Ridge(alpha=1.0)  # Adjust alpha for regularization strength
ridge_model.fit(X_train, y_train)

# Evaluate models
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    return mse

lr_mse = evaluate_model(lr_model, X_test, y_test)
lasso_mse = evaluate_model(lasso_model, X_test, y_test)
ridge_mse = evaluate_model(ridge_model, X_test, y_test)

print("Linear Regression MSE:", lr_mse)
print("Lasso Regression MSE:", lasso_mse)
print("Ridge Regression MSE:", ridge_mse)
-----------------------------------------------------------------------



import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Lasso
from sklearn.feature_selection import SelectFromModel
from sklearn.metrics import mean_squared_error

# Generate some example data
X, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=42)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale features using StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Linear Regression with hyperparameter tuning
param_grid = {'fit_intercept': [True, False]}  # Hyperparameters to tune
lr_grid = GridSearchCV(LinearRegression(), param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')
lr_grid.fit(X_train_scaled, y_train)
best_lr_model = lr_grid.best_estimator_

# Feature selection using Lasso regularization
lasso_model = Lasso(alpha=0.1)  # You can adjust alpha for regularization strength
lasso_model.fit(X_train_scaled, y_train)
selected_features = np.where(lasso_model.coef_ != 0)[0]

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.bar(range(len(lasso_model.coef_)), lasso_model.coef_, color='skyblue')
plt.xlabel('Feature Index')
plt.ylabel('Coefficient')
plt.title('Feature Importance (Lasso Regression)')
plt.show()

# Select features
X_train_selected = X_train_scaled[:, selected_features]
X_test_selected = X_test_scaled[:, selected_features]

# Retrain the model using selected features
best_lr_model.fit(X_train_selected, y_train)

# Evaluate model
y_pred = best_lr_model.predict(X_test_selected)
mse = mean_squared_error(y_test, y_pred)
print("Linear Regression MSE:", mse)
